{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b41eb6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "DATADIR = \"C:/Users/PC PRO ULTRA RAPIDE/Desktop/Projects/artificial intelligence/ml/sign-lang/sign-lang-dataset/\"\n",
    "\n",
    "ALPHABETS = [\n",
    "    \"ain\", \"al\", \"aleff\", \"ba\", \"dad\", \"dal\", \"dhad\", \"fa\", \"ghain\", \"ha\",\n",
    "    \"haae\", \"jeem\", \"kaaf\", \"khaa\", \"la\", \"laam\", \"meem\", \"nun\", \"qaf\", \"ra\", \"saad\",\n",
    "    \"seen\", \"sheen\", \"taae\", \"taae2\", \"thaae\", \"thdad\", \"waw\", \"ya\", \"zay\" ]\n",
    "\n",
    "train_ds = []\n",
    "\n",
    "for alphabet in ALPHABETS:\n",
    "    path = os.path.join(DATADIR, alphabet)\n",
    "    class_num = ALPHABETS.index(alphabet)\n",
    "    for img in os.listdir(path):        \n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        train_ds.append([img_array, class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aadccc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51174 files belonging to 30 classes.\n",
      "Using 40940 files for training.\n",
      "Found 51174 files belonging to 30 classes.\n",
      "Using 10234 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATADIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATADIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "918c1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        #layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75f89379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c9732af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "320\n",
      "51200\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "print((len(train_ds)+len(val_ds))*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ee15c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 64, 64, 3)    0           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_7 (Rescaling)         (None, 64, 64, 3)    0           sequential_10[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 32)   896         rescaling_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 32, 32, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 32, 32, 32)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 64)   18496       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 32, 32, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 32, 32, 64)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 32, 32, 64)   0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_63 (SeparableC (None, 32, 32, 128)  8896        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 32, 32, 128)  512         separable_conv2d_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 32, 32, 128)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_64 (SeparableC (None, 32, 32, 128)  17664       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 32, 32, 128)  512         separable_conv2d_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 16, 16, 128)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 128)  8320        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 16, 16, 128)  0           max_pooling2d_28[0][0]           \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 16, 128)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_65 (SeparableC (None, 16, 16, 256)  34176       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 256)  1024        separable_conv2d_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 16, 256)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_66 (SeparableC (None, 16, 16, 256)  68096       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 256)  1024        separable_conv2d_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 8, 8, 256)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 256)    33024       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 256)    0           max_pooling2d_29[0][0]           \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 256)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_67 (SeparableC (None, 8, 8, 512)    133888      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 512)    2048        separable_conv2d_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 512)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_68 (SeparableC (None, 8, 8, 512)    267264      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 512)    2048        separable_conv2d_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 4, 4, 512)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 512)    131584      add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 4, 4, 512)    0           max_pooling2d_30[0][0]           \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 512)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_69 (SeparableC (None, 4, 4, 728)    378072      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 4, 728)    2912        separable_conv2d_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 728)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_70 (SeparableC (None, 4, 4, 728)    537264      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 4, 728)    2912        separable_conv2d_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 2, 2, 728)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 2, 2, 728)    373464      add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2, 2, 728)    0           max_pooling2d_31[0][0]           \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_71 (SeparableC (None, 2, 2, 1024)   753048      add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 1024)   4096        separable_conv2d_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 1024)         0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024)         0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 30)           30750       dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,812,374\n",
      "Trainable params: 2,803,638\n",
      "Non-trainable params: 8,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model = make_model(input_shape= image_size + (3,), num_classes=30)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26dd533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 1484s 1s/step - loss: 0.8476 - accuracy: 0.7333 - val_loss: 0.7386 - val_accuracy: 0.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC PRO ULTRA RAPIDE\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f628d2d30>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('alphabet.model')  # save the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
